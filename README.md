# chat-llama
A sleek Web UI to chat with Metaâ€™s LLaMA 2, 3, and 3.2 models locally using Ollama

# llama-ui: Local Web Chat with LLaMA 2, 3, and 3.2 using Ollama

Welcome to **llama-ui** â€” a lightweight and elegant Web UI built for chatting with Meta's powerful LLaMA models running locally through **[Ollama](https://ollama.com)**. Whether you're a developer, researcher, or enthusiast, this interface gives you a clean and easy way to interact with LLaMA 2, 3, or 3.2 directly on your machine.

---

---

## ðŸš€ Key Features

-  Supports **LLaMA 2**, **LLaMA 3**, and **LLaMA 3.2** via Ollama
-  FastAPI-powered **Python backend**
-  Clean, minimal **HTML + JavaScript frontend**
-  Simple integration with Ollamaâ€™s local LLM API
-  Easy to expand and customize for advanced chatbots

---

# Prerequisites

Make sure you have the following installed:

- [Python 3.11](https://www.python.org/downloads/release/python-3110/) (Recommended)
- [Ollama](https://ollama.com) â€“ local LLM engine
- A modern browser

---





